# Training library for fine-tuning ViTs (Vision Transformer) models on custom datasets

## Installation âš™ï¸ 


### Create a new environment conda
```bash
conda env create
conda activate vitstrain
```

### If you prefer pyenv

```bash
pyenv virtualenv 3.11.0 vitstrain
pyenv activate vitstrain
pip install -r requirements.txt
```

## Training ğŸš€  

Step 1. Download the labeled data and crop the images using the [mbari-aidata pip module](https://github.com/mbari-org/aidata)
 
Data should be in folder per class with and required stats.json file. 
For example, the folder structure should look like this:

```
â””â”€â”€ crops
    â”œâ”€â”€ cats
    â”‚Â Â  â”œâ”€â”€ cat.0.jpg
    â”‚Â Â  â”œâ”€â”€ cat.1.jpg
    â”‚Â Â  â”œâ”€â”€ cat.10.jpg
    â”‚Â Â  â”œâ”€â”€ cat.100.jpg 
    â”œâ”€â”€ dogs
    â”‚Â Â  â”œâ”€â”€ dog.0.jpg
    â”‚Â Â  â”œâ”€â”€ dog.1.jpg
    â”‚Â Â  â”œâ”€â”€ dog.10.jpg
    â”‚Â Â  â”œâ”€â”€ dog.100.jpg 
    â””â”€â”€ stats.json
```                                                                                                                                                                                          

The stats.json file should contain the following information:

```json
{ 
    "total_labels": {
        "cats": 100,
        "dogs": 100
    }
}
```

Here, we are using the `config_uav.yml` configuration file to download the UAV dataset,
download the data, crop the images, and resize them to 224x224 pixels.
TODO: add more details about the configuration file.

```bash
pip install mbari-aidata
cd aidata
python aidata download \
        --config config_uav.yml \
        --base-path $PWD  \
        --version Baseline \
        --token $TATOR_TOKEN --crop-roi --resize 224
```

Step 2. Train the model

```bash
python src/fine_tune_vit.py \
        --data-path $PWD/Baseline/crops \
        --base-model google/vit-base-patch16-224-in21k
        --model-name mbari-uav-vit-b16 \
        --epochs 30
```

Example output:
```text
/Volumes/DeepSea-AI/models/UAV/mbari-uav-vit-b16-20250108/
â”œâ”€â”€ all_results.json
â”œâ”€â”€ checkpoint-1710
â”‚Â Â  â”œâ”€â”€ config.json
â”‚Â Â  â”œâ”€â”€ model.safetensors
â”‚Â Â  â”œâ”€â”€ optimizer.pt
â”‚Â Â  â”œâ”€â”€ preprocessor_config.json
â”‚Â Â  â”œâ”€â”€ rng_state.pth
â”‚Â Â  â”œâ”€â”€ scheduler.pt
â”‚Â Â  â”œâ”€â”€ trainer_state.json
â”‚Â Â  â””â”€â”€ training_args.bin
â”œâ”€â”€ config.json
â”œâ”€â”€ confusion_matrix_mbari-uav-vit-b16-20250108_2025-01-08 073852.png
â”œâ”€â”€ eval_results.json
â”œâ”€â”€ loss_curve_mbari-uav-vit-b16-20250108_2025-01-08_073852.png
â”œâ”€â”€ model.safetensors
â”œâ”€â”€ preprocessor_config.json
â””â”€â”€ training_args.bin
```

To remap the classes, use the `--remap` flag, passing in a file with a json formatted dictionary


```json

{
    "oldname" : "newname"
}
```

For example

```json
{
    "cats" : "felines",
    "dogs" : "canines"
}
```

THen a

```bash
python src/fine_tune_vit.py \
        ...
        --remap remap.json
```

![docs/imgs/confusion_matrix.png](./docs/imgs/confusion_matrix.png)
![docs/imgs/loss_curve.png](./docs/imgs/loss_curve.png)

last updated: 2025-03-29
